---
title: "Homework 6"
author: "Yishi Wang"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)
```
# Problem 1
## Data import and clean
Import data, create the city_state variable, and filter unwanted states:
```{r}
homicides = read_csv("local_files/homicide-data.csv") |>
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = na_if(victim_age, "Unknown"),
    victim_age = as.numeric(victim_age)
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  )
```

## Baltimore model
First get the data for Baltimore:
```{r}
baltimore =
  homicides |>
  filter(city_state == "Baltimore, MD")
```

Use glm function to fit a logistic regression model. Treating resolved vs unresolved as the outcome and victim age, sex and race as predictors.
```{r}
baltimore_fit = glm(solved ~ victim_age + victim_sex + victim_race,
      family = binomial, data = baltimore)

baltimore_or = baltimore_fit |>
  broom::tidy(conf.int = TRUE, exponentiate = TRUE)

baltimore_or
```

Now if we look at the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male to female alone:
```{r}
baltimore_or |>
  filter(term == "victim_sexMale")
```

We can see that the conf interval of the adjusted OR is (0.324, 0.558) and the estimate OR is 0.426. We can say the odds that a homicide is solved are about 0.574 lower for male victims than female victims in Baltimore.

## All cities model
Similarly, we use glm function to fit a model for all cities and look at the estimate and confidence interval of OR for solving homicides comparing male to female alone:
```{r warning=FALSE}
city_or =
  homicides |>
  group_by(city_state) |>
  nest() |>
  mutate(
    fit = purrr::map(data, ~ glm(solved ~ victim_age + victim_sex + victim_race,
                                 family = binomial, data = .x)),
    results = purrr::map(fit, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |>
  select(city_state, results) |>
  unnest(results) |>
  filter(term == "victim_sexMale")

city_or
```

## Plotting
Plot the OR and confidence interval for each city based our previous result:
```{r dpi=300, fig.width=7, fig.height=8}
city_or_plot =
  city_or |>
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
  coord_flip() +
  labs(
    x = "City",
    y = "Adjusted OR",
    title = "Adjusted odds of a homicide being solved (male vs female)"
  )

city_or_plot

```

We can see that Albuquerque, NM has the highest adjusted OR and New York, NY has the lowest adjusted OR, while a higher adjusted OR means bigger chance a homicide is solved for male than female in that city. Note that all cities except the top 5 have a OR < 1, this means a homicide is more likely to be solved for female victims than male victims in most cities.

# Problem 2
## Data import
Import Central Park data from p8105.dataset:
```{r}
data("weather_df")

weather_cp = 
  weather_df |>
  filter(name == "CentralPark_NY")
```

## Bootstraping
Create 5000 bootstrap samples and extract r^2 and (beta_tmin / beta_prcp) based on provided formula
```{r}
set.seed(1)

boot_results =
  weather_cp |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    est = map(strap, ~ {
      dat = as_tibble(.x)
      fit = lm(tmax ~ tmin + prcp, data = dat)
      r_sq = broom::glance(fit)$r.squared
      coefs = broom::tidy(fit)
      beta_tmin = coefs |> filter(term == "tmin") |> pull(estimate)
      beta_prcp = coefs |> filter(term == "prcp") |> pull(estimate)

      tibble(
        r_sq = r_sq,
        beta_ratio = beta_tmin / beta_prcp
      )
    })
  ) |>
  unnest(est)
```

## Plotting Distributions
We first plot the distributions squared r:
```{r}
boot_results |>
  ggplot(aes(x = r_sq)) +
  geom_histogram()
```

Most of our bootstrap samples have a squared r around 0.9, and this implies a strong linear relationship. The model prediction should be stable most of the times. Next, for beta ratios, we perform log scaling to handle the large span of data:
```{r}
boot_results |>
  ggplot(aes(x = beta_ratio)) +
  geom_histogram() +
  scale_x_log10()

```

We see that most beta ratios lie between 100 and 10000, and implies that beta_1 (tmin) has a strong impact on tmax while beta_2 (prcp) almost has none. Namely, tmin is the main predictor of tmax.

## Identifying CI
First get the CI for squared r:
```{r}
boot_results |>
  summarize(
    r_sq_low  = quantile(r_sq, 0.025),
    r_sq_high = quantile(r_sq, 0.975),
  )
```

The 95% confidence interval for squared r is (0.894, 0.928). Similarly, for beta ratios:
```{r}
boot_results |>
  summarise(
    ratio_low  = quantile(beta_ratio, 0.025),
    ratio_high = quantile(beta_ratio, 0.975)
  )
```

The 95% confidence interval for squared r is (-5616, 4587)








