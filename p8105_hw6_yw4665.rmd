---
title: "Homework 6"
author: "Yishi Wang"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE
  )
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(purrr)

```
# Problem 1
### Data import and clean
Import data, create the city_state variable, and filter unwanted states:
```{r}
homicides = read_csv("local_files/homicide-data.csv") |>
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = na_if(victim_age, "Unknown"),
    victim_age = as.numeric(victim_age)
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  )
```

### Baltimore model
First get the data for Baltimore:
```{r}
baltimore =
  homicides |>
  filter(city_state == "Baltimore, MD")
```

Use glm function to fit a logistic regression model and then apply tidy to it. Treating resolved vs unresolved as the outcome and victim age, sex and race as predictors.
```{r}
baltimore_fit = glm(solved ~ victim_age + victim_sex + victim_race,
      family = binomial, data = baltimore)

baltimore_or = baltimore_fit |>
  broom::tidy(conf.int = TRUE, exponentiate = TRUE)

baltimore_or
```

Now if we look at the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male to female alone:
```{r}
baltimore_or |>
  filter(term == "victim_sexMale")
```

We can see that the conf interval of the adjusted OR is (0.324, 0.558) and the estimate OR is 0.426. We can say the odds that a homicide is solved are about 0.574 lower for male victims than female victims in Baltimore.

### All cities model
Similarly, we use glm function to fit a model for all cities and look at the estimate and confidence interval of OR for solving homicides comparing male to female alone:
```{r warning=FALSE}
city_or =
  homicides |>
  group_by(city_state) |>
  nest() |>
  mutate(
    fit = map(data, ~ glm(solved ~ victim_age + victim_sex + victim_race,
                                 family = binomial, data = .x)),
    results = map(fit, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |>
  select(city_state, results) |>
  unnest(results) |>
  filter(term == "victim_sexMale")

city_or
```

### Plotting
Plot the OR and confidence interval for each city based our previous result:
```{r dpi=300, fig.width=7, fig.height=8}
city_or_plot =
  city_or |>
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
  coord_flip() +
  labs(
    x = "City",
    y = "Adjusted OR",
    title = "Adjusted odds of a homicide being solved (male vs female)"
  )

city_or_plot

```

We can see that Albuquerque, NM has the highest adjusted OR and New York, NY has the lowest adjusted OR, while a higher adjusted OR means bigger chance a homicide is solved for male than female in that city. Note that all cities except the top 5 have a OR < 1, this means a homicide is more likely to be solved for female victims than male victims in most cities.

# Problem 2
### Data import
Import Central Park data from p8105.dataset:
```{r}
data("weather_df")

weather_cp = 
  weather_df |>
  filter(name == "CentralPark_NY")
```

### Bootstraping
Create 5000 bootstrap samples and extract r^2 and (beta_tmin / beta_prcp) based on provided formula
```{r}
set.seed(1)

boot_results =
  weather_cp |>
  bootstrap(n = 5000) |>
  mutate(
    est = map(strap, ~ {
      dat = as_tibble(.x)
      fit = lm(tmax ~ tmin + prcp, data = dat)
      r_sq = broom::glance(fit)$r.squared
      coefs = broom::tidy(fit)
      beta_tmin = coefs |> filter(term == "tmin") |> pull(estimate)
      beta_prcp = coefs |> filter(term == "prcp") |> pull(estimate)

      tibble(
        r_sq = r_sq,
        beta_ratio = beta_tmin / beta_prcp
      )
    })
  ) |>
  unnest(est)
```

### Plotting Distributions
We first plot the distributions squared r:
```{r}
boot_results |>
  ggplot(aes(x = r_sq)) +
  geom_histogram()
```

Most of our bootstrap samples have a squared r around 0.9, and this implies a strong linear relationship. The model prediction should be stable most of the times. Next, for beta ratios, we perform log scaling to handle the large span of data:
```{r}
boot_results |>
  ggplot(aes(x = beta_ratio)) +
  geom_histogram() +
  scale_x_log10()

```

We see that most beta ratios lie between 100 and 10000, and implies that beta_1 (tmin) has a strong impact on tmax while beta_2 (prcp) almost has none. Namely, tmin is the main predictor of tmax.

### Identifying CI
First get the CI for squared r:
```{r}
boot_results |>
  summarize(
    r_sq_low  = quantile(r_sq, 0.025),
    r_sq_high = quantile(r_sq, 0.975),
  )
```

The 95% confidence interval for squared r is (0.894, 0.928). Similarly, for beta ratios:
```{r}
boot_results |>
  summarise(
    ratio_low  = quantile(beta_ratio, 0.025),
    ratio_high = quantile(beta_ratio, 0.975)
  )
```

The 95% confidence interval for squared r is (-5616, 4587)

# Problem 3
### Data import and cleaning
Import data, factor factoralble variables, and omit missing data (pnumlbw and
pnumgsa only contain 0 values):
```{r}
birthweight = read_csv("local_files/birthweight.csv") |>
  janitor::clean_names() |>
  mutate(
    babysex = factor(babysex),
    malform = factor(malform),
    frace   = factor(frace),
    mrace   = factor(mrace)
  ) |>
  select(-pnumlbw, -pnumsga)
```

### Modeling
All of the following variables should be closely related to birthweight (based on intuitive and a small look-up):
body size, gestational age, pre-pregnancy BMI, previous birth count, smoking during pregnancy, and weight gain.

Therefore we use these variables to build a simple linear model:
```{r}
birthweight_fit = lm(bwt ~ blength + bhead + gaweeks + ppbmi + smoken + wtgain, data = birthweight)
summary(birthweight_fit)
```

Now we make model prediction and residuals against the fitted values and plot them:
```{r}
birthweight_aug = birthweight |>
  add_predictions(birthweight_fit) |>
  add_residuals(birthweight_fit)

birthweight_aug |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0) +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Residual plot for birthweight"
  )
```

We can see that the residual is symmetric about 0, and the mean residual is flat across predicted values. Despite a few outliers, our linear model should be stable. 

### Model Comparison
First build the main effects model and the fully interacted model. Then perform cross-validated prediction with 20 folds:
```{r}
set.seed(1)

cv_df = crossv_mc(birthweight, 20)
cv_results = cv_df |>
  mutate(
    fit1 = map(train, ~lm(bwt ~ blength + bhead + gaweeks + ppbmi + smoken + wtgain, data = .x)),
    fit2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    fit3 = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))
  )

```

Compare the prediction errors:
```{r}
cv_results = cv_results |>
  mutate(
    rmse1 = map2_dbl(fit1, test, ~ rmse(model = .x, data = .y)),
    rmse2 = map2_dbl(fit2, test, ~ rmse(model = .x, data = .y)),
    rmse3 = map2_dbl(fit3, test, ~ rmse(model = .x, data = .y))
  )
cv_results |>
  select(rmse1, rmse2, rmse3) |>
  pivot_longer(everything(), names_to="model", values_to="rmse") |>
  group_by(model) |>
  summarize(mean_rmse = mean(rmse))
```
Based on 20-fold cross-validation, our proposed model had the lowest average RMSE (284), meaning it has the best performance among the three models.






